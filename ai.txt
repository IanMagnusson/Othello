Ian Magnusson
CS5001
Homework 7
December 2nd, 2018

notes on AI design:

- Did you attempt to make your computer player very smart -- i.e., do something more clever than just pick a random legal move?

Yes, in it's current state it prioritizes positions (corners, then edges, then neutral positions in the middle, then dangerous spaces adjacent to edges, and finally spaces adjacent to corners), and it also looks into the outcome of the move for the next board. It judges the outcome differently before and after a threshold of how full the board is. In the early game it attempts to maximize the number of its own moves open minus the number of the humans moves. In the end game it gets aggressive and picks moves that flip the most stones.

- If so, were you able to accomplish this? Is your computer player as smart as you would like?

I realized late in the process just how hard it would be to test the AI, because the amount of work it takes to manually test any but the most simple and contrived boards. Nevertheless to the best of my ability to test it, seems to be behaving as predicted. I'm less certain that these are actually the best possible strategies. Originally I had hoped to create a more general approach that would parameterize the AI's behavior on the basis of general features. The idea was to make a framework that I could later approach with ML techniques to optimize the parameters of the AI's behavior. Sadly I have had to choose between learning the math I would need for that and focusing on the more pressing math studies in Discrete Structures. I still believe that I have made a good Othello platform that efficiently computes changes in board state without having to touch all objects.

- How did you determine which piece to play next?  Tell us about your “pick next move” algorithm.

pick_move sorts the current players moves into lists based on the different categories of positions. It then take the best available category and assesses each move in the category on the basis of an outcome evaluation. This evaluation differs based on the previously discussed threshold state. In the end game state the algorithm simply queries each move for how many stones it will flip (something it already tracks every time it is updated). In the beginning game state the algorithm is considerably less efficient. It makes a deep copy of the board and tests each move and then counts the resulting moves that are then available. This could be made more efficient by using the test board of the selected move to continue playing on rather than having to compute the selected move twice (once for testing and again on the main play board). I choose to focus my efforts on efficiency in the underlying board platform rather than in the experimental AI, however, as I believe I will be better prepared to work on the AI in the future. 

- How often did your computer program beat you, or your friends, or whoever tested it out for you?

After I got the AI to its current state I was unable to beat it for a while, and I still only beat it every now and then. Its deterministic behavior would make it vulnerable to an opponent with more time to consider moves.

- How would you improve it in the future?

I would precede as originally planned and find a way to output a probability distribution of all possible moves instead of a single determined pick. This distribution would be weighted by parameters that could be optimized with ML. This would require defining some kind of a reward function (ie a way to judge the desirability of an outcome board state). This seems like the most interesting problem to solve as the game of Othello is small enough that it is possible to Brute force with enough time.
